{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align:left;\">\n",
        "  <a href=\"https://code213.tech/\" target=\"_blank\">\n",
        "    <img src=\"../images/code213.PNG\" alt=\"QWorld\">\n",
        "  </a>\n",
        "  <p><em>prepared by Latreche Sara</em></p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7brZmVyP6jc"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgr91hrQP5eZ"
      },
      "source": [
        "\n",
        "###  Flavors of Boosting\n",
        "\n",
        "In this notebook, we build a **photometric redshift estimator** using several **boosting methods**, including:\n",
        "\n",
        "- **AdaBoost**\n",
        "- **Gradient Boosted Trees (GBM)**\n",
        "- **Histogram-Based Gradient Boosting (HistGBM)**\n",
        "- **XGBoost**\n",
        "\n",
        "We also explore how to improve model performance using **RandomizedSearchCV** for hyperparameter tuning.\n",
        "\n",
        "**Objective**:  \n",
        "Estimate **photometric redshifts** from observations of galaxy magnitudes in six photometric bands:  \n",
        "**u, g, r, i, z, y**.\n",
        "---\n",
        "\n",
        " **Reference Paper**:  \n",
        "We aim to reproduce and improve upon the results of this paper:  \n",
        "[Zou et al., 2019 — arXiv:1903.08174](https://arxiv.org/abs/1903.08174)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9NjIhspPYbf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "\n",
        "font = {'size'   : 16}\n",
        "matplotlib.rc('font', **font)\n",
        "matplotlib.rc('xtick', labelsize=14)\n",
        "matplotlib.rc('ytick', labelsize=14)\n",
        "#matplotlib.rcParams.update({'figure.autolayout': True})\n",
        "matplotlib.rcParams['figure.dpi'] = 300"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjaIzQgfQMnr"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate, KFold, cross_val_predict, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l393qZd5Qijw"
      },
      "source": [
        "### We can read the data set with the selections applied in the previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBInBr5UQhSa"
      },
      "outputs": [],
      "source": [
        "sel_features = pd.read_csv('sel_features.csv', sep = '\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ItzjK0xQn-e"
      },
      "outputs": [],
      "source": [
        "sel_target = pd.read_csv('sel_target.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuyR3Lv4QooF"
      },
      "outputs": [],
      "source": [
        "sel_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuZjhZ-FWgME"
      },
      "outputs": [],
      "source": [
        "sel_target.values.ravel() #changes shape to 1d row-like array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpd9-Vr_WnyQ"
      },
      "source": [
        "#### In the notebook \"BoostingDecisions\", we showed that for AdaBoost, stacking learners that are too weak doesn't help."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X34Y9hFsWsMo"
      },
      "source": [
        "This allows us to run a more informed parameter optimization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7po3reXWi2F"
      },
      "outputs": [],
      "source": [
        "# Step 1: Define the parameter grid for the AdaBoostRegressor.\n",
        "# Each key corresponds to a parameter, and its values are the options to try.\n",
        "\n",
        "parameters = {\n",
        "    # The maximum depth of each decision tree (base learner).\n",
        "    # Shallow trees (e.g., 6) are weaker learners; deeper trees (10, None) are stronger.\n",
        "\n",
        "    # Type of loss function to minimize when updating weights:\n",
        "    # 'linear' treats all errors equally, 'square' penalizes larger errors more.\n",
        "\n",
        "    # Number of boosting stages (iterations).\n",
        "    # More estimators = potentially better performance but longer training.\n",
        "    'n_estimators': [20, 50, 100],\n",
        "\n",
        "    # Learning rate shrinks the contribution of each tree.\n",
        "    # Smaller values (like 0.3) mean slower but often more robust learning.\n",
        "    # Larger values (like 1.0) can speed up learning but may overfit.\n",
        "}\n",
        "\n",
        "# Calculate total number of model combinations: 3 depths × 2 losses × 3 n_estimators × 3 learning_rates = 54 models\n",
        "\n",
        "# Step 2: Instantiate the GridSearchCV object with 5-fold cross-validation\n",
        "model =\n",
        "    ,  # Boosting model using decision trees\n",
        "      # Grid of hyperparameters to search\n",
        "      # 5-fold CV with shuffling\n",
        "      # Print progress\n",
        "     # Use 4 CPU cores for parallel processing\n",
        "   # Store training scores as well\n",
        ")\n",
        "\n",
        "# Step 3: Fit the model to the selected features and target\n",
        "\n",
        "# Step 4: Print the best score and the combination of parameters that gave it\n",
        "      # Format R^2 score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICDVV3WJXi-k"
      },
      "source": [
        "We can take a look at the winning model scores; in this case, we also pay attention to the standard deviation of test scores, because we want to know what differences are statistically significant when we compare different models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMY6_Hy2Xjse"
      },
      "outputs": [],
      "source": [
        "### Grouped Grid Search Results\n",
        "\n",
        "\n",
        "#### 1. `base_estimator__max_depth`\n",
        "#This controls how deep each decision tree is:\n",
        "#- Smaller depths (e.g., 6) limit model complexity (weaker learners).\n",
        "#- Larger depths (e.g., None = unlimited) allow more complex models.\n",
        "\n",
        "#### 2. `learning_rate`\n",
        "#Controls how much each tree contributes to the overall prediction:\n",
        "#- Smaller values like `0.3` lead to slower learning but potentially better generalization.\n",
        "#- Larger values like `1.0` can speed up training but risk overshooting the optimal solution.\n",
        "\n",
        "#### 3. `n_estimators`\n",
        "#The number of boosting rounds (trees):\n",
        "#- Too few may underfit.\n",
        "#- Too many can overfit unless regularized (via `learning_rate`).\n",
        "\n",
        "#### 4. `loss`\n",
        "#Specifies the loss function for regression:\n",
        "#- `'linear'`: emphasizes absolute differences.\n",
        "#- `'square'`: penalizes large errors more (sensitive to outliers).\n",
        "\n",
        "#By grouping and averaging scores, we gain insights into which parameter values are most effective overall.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35xM7NjlYhAZ"
      },
      "source": [
        "We can see that the standard deviation is 0.03 - giving us a hint of what's significant - and that a few different models have similar scores. If you change the random seed in the cross validation, the scores will change by a similar amount, and the best model may change as well.\n",
        "\n",
        "Additionally, the resulting scores will not be exactly reproducible because there is another random component in the adaptive learning set (this means that if you run the cross_validate function using the best model from above, you might get a different average score!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ruQIZ5cYo-P"
      },
      "source": [
        "Let's pick the best model and check the scores. We should do nested cross validation to get the generalization errors right - but if we are just comparing models, this is ok."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPZIXlOcYPyu"
      },
      "outputs": [],
      "source": [
        "bm = model.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMPtQYhzYs95"
      },
      "outputs": [],
      "source": [
        "# Use cross_val_predict to get cross-validated predictions from the model `bm`\n",
        "# sel_features: the input features\n",
        "# sel_target: the target values, flattened using .values.ravel()\n",
        "# cv: apply 5-fold cross-validation with shuffling and fixed random state\n",
        "# Store the predicted values in y_pred_bm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncZpDa1pZ6AQ"
      },
      "source": [
        "Calculate outlier fraction and NMAD:\n",
        "###  What is NMAD (Normalized Median Absolute Deviation)?\n",
        "\n",
        "When evaluating regression performance—especially in astronomy and photometric redshift estimation—we often encounter **outliers** (extreme prediction errors) that can distort typical error metrics like RMSE or standard deviation.\n",
        "\n",
        "To handle this, we use **NMAD**, a robust statistic that provides a more reliable measure of the **spread of errors**, even in the presence of outliers.\n",
        "\n",
        "---\n",
        "\n",
        "####  Why is NMAD important?\n",
        "\n",
        "- **Robust to outliers**: Unlike standard deviation, NMAD is based on the **median**, not the mean, so a few large errors don’t overly influence the result.\n",
        "- **Standardized**: It normalizes the error with respect to $z_{\\text{spec}}$, the true redshift, allowing fair comparison across objects.\n",
        "- **Recommended in astronomy**: Widely adopted in photometric redshift estimation literature (e.g. in Ilbert et al. 2006 and Sánchez et al. 2014).\n",
        "\n",
        "---\n",
        "\n",
        "#### NMAD Formula\n",
        "\n",
        "$$\n",
        "\\text{NMAD} = 1.4826 \\times \\text{median} \\left( \\left| \\frac{\\Delta z - \\text{median}(\\Delta z)}{1 + z_{\\text{spec}}} \\right| \\right)\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "- $\\Delta z = z_{\\text{phot}} - z_{\\text{spec}}$ is the prediction error\n",
        "- $z_{\\text{phot}}$ is the predicted redshift\n",
        "- $z_{\\text{spec}}$ is the true redshift\n",
        "- The constant **1.4826** scales the result to match the standard deviation for a Gaussian distribution\n",
        "\n",
        "---\n",
        "\n",
        "####  In Practice\n",
        "\n",
        "- Use NMAD to evaluate the **typical scatter** of your predictions.\n",
        "- Use it **alongside outlier fraction** and **R²** for a complete view of model performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FZ3xBKhZkgg"
      },
      "outputs": [],
      "source": [
        "# Compute the outlier fraction\n",
        "# An outlier is defined as a prediction where the absolute error exceeds 0.15 × (1 + true value)\n",
        "\n",
        "\n",
        "# Compute the NMAD (Normalized Median Absolute Deviation)\n",
        "# Formula: NMAD = 1.48 × median(|Δz| / (1 + z_spec))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0ahss__ZV-r"
      },
      "outputs": [],
      "source": [
        "print(np.round(len(np.where(np.abs(sel_target.values.ravel()-y_pred_bm)>0.15*(1+sel_target.values.ravel()))[0])/len(sel_target.values.ravel()),3))\n",
        "\n",
        "print(np.round(1.48*np.median(np.abs(sel_target.values.ravel()-y_pred_bm)/(1 + sel_target.values.ravel())),3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpCJXxhia5O3"
      },
      "source": [
        "These are actually better than what we obtained for the Random Forests model! But is the difference statistically significant? One way to explore this is by generating several sets of predictions, and calculating their standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vSWkXopaxcD"
      },
      "outputs": [],
      "source": [
        "# Pick 8 different random seeds from the range [0, 100)\n",
        "  # Used to vary the random state in cross-validation\n",
        "\n",
        "# Initialize arrays to store Outlier Fraction (OLF) and NMAD for each seed\n",
        "\n",
        "\n",
        "# Loop over each random seed\n",
        "  # Track progress of the loop\n",
        "\n",
        "    # Perform cross-validated predictions using the current seed\n",
        "\n",
        "\n",
        "    # Compute outlier fraction: where absolute error > 0.15 × (1 + true redshift)\n",
        "\n",
        "\n",
        "    # Compute NMAD: 1.48 × median of absolute normalized error\n",
        "\n",
        "\n",
        "# Print the mean and standard deviation of OLF and NMAD across seeds\n",
        "print('OLF avg/std:, {0:.5f}, {1:0.5f}'.format(olf.mean(), olf.std()))\n",
        "print('NMAD avg/std:, {0:.5f}, {1:0.5f}'.format(NMAD.mean(), NMAD.std()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfwTI3n5a4TH"
      },
      "outputs": [],
      "source": [
        "# Pick 8 different random seeds from the range [0, 100)\n",
        "seeds = np.random.choice(100, 8, replace=False)  # Used to vary the random state in cross-validation\n",
        "\n",
        "# Initialize arrays to store Outlier Fraction (OLF) and NMAD for each seed\n",
        "olf = np.zeros(8)\n",
        "NMAD = np.zeros(8)\n",
        "\n",
        "# Loop over each random seed\n",
        "for i in range(8):\n",
        "    print('Iteration', i)  # Track progress of the loop\n",
        "\n",
        "    # Perform cross-validated predictions using the current seed\n",
        "    ypred = cross_val_predict(\n",
        "        bm,\n",
        "        sel_features,\n",
        "        sel_target.values.ravel(),\n",
        "        cv=KFold(n_splits=5, shuffle=True, random_state=seeds[i])\n",
        "    )\n",
        "\n",
        "    # Compute outlier fraction: where absolute error > 0.15 × (1 + true redshift)\n",
        "    olf[i] = (\n",
        "        len(np.where(np.abs(sel_target.values.ravel() - ypred) > 0.15 * (1 + sel_target.values.ravel()))[0])\n",
        "        / len(sel_target.values.ravel())\n",
        "    )\n",
        "\n",
        "    # Compute NMAD: 1.48 × median of absolute normalized error\n",
        "    NMAD[i] = (\n",
        "        1.48 * np.median(np.abs(sel_target.values.ravel() - ypred) / (1 + sel_target.values.ravel()))\n",
        "    )\n",
        "\n",
        "# Print the mean and standard deviation of OLF and NMAD across seeds\n",
        "print('OLF avg/std:, {0:.5f}, {1:0.5f}'.format(olf.mean(), olf.std()))\n",
        "print('NMAD avg/std:, {0:.5f}, {1:0.5f}'.format(NMAD.mean(), NMAD.std()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2kHN_AZbdbZ"
      },
      "source": [
        "The result seems to be relatively solid, indicating that Boosting methods might be slightly better than RF when we take into account not just the R2 score, but the specific metrics we are monitoring for this problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP5xfnP0bjiK"
      },
      "source": [
        "### The next step is to compare Adaptive Boosting with different Gradient Boosted Trees algorithms.\n",
        "\n",
        "We begin by using sklearn's GBM, then we move on to the lighter version, HistGBM, and finally we consider one of the most popular GBT-based algorithm, XGBoost.\n",
        "\n",
        "We also take a look at the possibility of using a Randomized Search instead of a Grid Search in order to speed up our optimization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19v1Vpckbd9l"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGVfJf9AbqzX"
      },
      "source": [
        "\n",
        "The parameters depend on the particular implementation.\n",
        "\n",
        "In the sklearn formulation, the parameters of each tree are essentially the same we have for Random Forests; additionally we have the \"learning_rate\" parameter, which dictates how much each tree contribute to the final estimator, and the \"subsample\" parameters, which allows one to use a < 1.0 fraction of samples and introduce some regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTdwEUYHbuT5"
      },
      "source": [
        "### We can run the optimization process for this algorithm on a similar grid to the one used for AdaBoost."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz3QDVG0bmyb"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "# This cell uses GridSearchCV to optimize hyperparameters of GradientBoostingRegressor.\n",
        "# On a typical machine, it may take several minutes to run (~4.5 minutes here).\n",
        "\n",
        "# Define the hyperparameter grid for the Gradient Boosting Regressor:\n",
        "parameters = {\n",
        "    'max_depth': [6, 10, None],                        # Depth of individual trees\n",
        "    'loss': ['squared_error', 'absolute_error'],       # Loss function used for optimization\n",
        "    'n_estimators': [20, 50, 100],                     # Number of boosting stages\n",
        "    'learning_rate': [0.1, 0.3, 0.5]                   # Shrinks contribution of each tree\n",
        "}\n",
        "\n",
        "# Compute the total number of models that will be tested during GridSearch\n",
        "\n",
        "# Instantiate the GridSearchCV object using 5-fold cross-validation\n",
        "      # The model to tune\n",
        "                   # The hyperparameter grid\n",
        "      # Cross-validation scheme\n",
        "                      # Verbosity level (prints progress)\n",
        "                     # Number of parallel jobs (use -1 to use all CPUs)\n",
        "          # Also store training scores\n",
        "\n",
        "# Fit the GridSearchCV model to the selected features and target\n",
        "\n",
        "# Print the best hyperparameters and the corresponding cross-validation score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgfSov9gcgTj"
      },
      "source": [
        "These are comparable to what we obtained with AdaBoost (slightly lower, typically). We can check what happens to the outlier fraction and NMAD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32cC2yIsccHJ"
      },
      "outputs": [],
      "source": [
        "# determie best model with method best_estimator\n",
        "bm ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZK6Fa-5cr-x"
      },
      "outputs": [],
      "source": [
        "y_pred_bm ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNeM8Srtcwrq"
      },
      "outputs": [],
      "source": [
        "print(np.round(len(np.where(np.abs(sel_target.values.ravel()-y_pred_bm)>0.15*(1+sel_target.values.ravel()))[0])/len(sel_target.values.ravel()),3))\n",
        "\n",
        "print(np.round(1.48*np.median(np.abs(sel_target.values.ravel()-y_pred_bm)/(1 + sel_target.values.ravel())),3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YZaW7cCc4Rg"
      },
      "source": [
        "\n",
        "Overall, the performance of the two algorithms is similar, but one important difference is timing. To explore exactly the same parameter space, GBR took ~ 3 times longer than AdaBoost. Additionally, gradient boosted methods typically require more estimators, and we should explore more regularization parameters (e.g. subsampling) as well. In a nutshell, it would be great to speed up things."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgFsOh7Xc9d3"
      },
      "source": [
        "### How can we make things faster?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGQfiw1YdCTe"
      },
      "source": [
        "We can improve on the time constraints in two ways: by switching to the histogram-based version of Gradient Boosting Regressor, and by using a Random Search instead of a Grid Search.\n",
        "\n",
        "HistGradientBoostingRegressor (inspired by [LightGBM](https://lightgbm.readthedocs.io/en/latest/)) works by binning the features into integer-valued bins (the default value is 256, but this parameter can be adjusted; note however that 256 is the maximum!), which greatly reduces the number of splitting points to consider, and results in a vast reduction of computation time, especially for large data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfQuoWDnc97h"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import HistGradientBoostingRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bm9wXpVdJgM"
      },
      "outputs": [],
      "source": [
        "# Perform hyperparameter tuning for the HistGradientBoostingRegressor\n",
        "\n",
        "# Define a grid of parameters:\n",
        "# - max_depth: controls tree depth (6, 10, or unlimited)\n",
        "# - loss: either squared error or absolute error\n",
        "# - max_iter: number of boosting iterations (20, 50, or 100)\n",
        "# - learning_rate: step size for updating predictions (0.1, 0.3, or 0.5)\n",
        "\n",
        "# Calculate the total number of models that will be trained as the product\n",
        "# of the number of options in each parameter list.\n",
        "\n",
        "# Instantiate GridSearchCV using:\n",
        "# - HistGradientBoostingRegressor as the estimator\n",
        "# - the defined parameter grid\n",
        "# - 5-fold cross-validation with shuffling and a fixed random state for reproducibility\n",
        "# - verbosity for tracking progress\n",
        "# - n_jobs=4 to parallelize across 4 cores\n",
        "# - return_train_score=True to store training scores\n",
        "\n",
        "# Fit the model to the selected training features and target values.\n",
        "\n",
        "# Print out the best cross-validation score and the corresponding parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOnBuh2GeE8X"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame from the cross-validation results stored in model.cv_results_\n",
        "# This includes training and validation metrics for each combination of hyperparameters.\n",
        "\n",
        "# Select and organize key columns for inspection:\n",
        "# - 'params': the hyperparameter configuration used\n",
        "# - 'mean_test_score': the average score on the validation folds\n",
        "# - 'std_test_score': the standard deviation of the validation scores\n",
        "# - 'mean_train_score': the average score on the training folds\n",
        "\n",
        "# Sort the results in descending order of mean_test_score to find the best-performing configurations.\n",
        "\n",
        "# Display the top entries in the sorted DataFrame to review the most promising models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-AwhxWndzpX"
      },
      "outputs": [],
      "source": [
        "scores = pd.DataFrame(model.cv_results_)\n",
        "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
        "                                                    ascending = False)\n",
        "scoresCV.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blaVaFy3eM3j"
      },
      "source": [
        "Even for this relatively small data set, this is much faster (about 15x faster than GradientBoostingRegressor), giving us a chance to explore a wider parameter space (e.g. more trees, more options for learning rate). The trade-off is that we obtain a slight decrease in performance, compared with GBR. However, the standard deviation of test scores over the 5 CV folds suggests that this difference is not statistically significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu0UY0lweQpd"
      },
      "source": [
        "Let's explore a wider parameter space here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvGWjvooeNXu"
      },
      "outputs": [],
      "source": [
        "#%%time\n",
        "# This block times the execution of a GridSearchCV optimization using HistGradientBoostingRegressor.\n",
        "# The process took approximately 2 minutes and 42 seconds.\n",
        "\n",
        "# Define the hyperparameter grid:\n",
        "# - 'max_depth': Controls tree depth; higher depth can capture more complexity but may overfit.\n",
        "# - 'loss': Specifies the loss function used for training ('squared_error' for MSE, 'absolute_error' for MAE).\n",
        "# - 'max_iter': Number of boosting iterations (trees); higher values improve performance but increase training time.\n",
        "# - 'learning_rate': Shrinks the contribution of each tree; lower rates need more iterations.\n",
        "# - 'early_stopping': Stops training when validation score stops improving; helps prevent overfitting.\n",
        "\n",
        "# Calculate the total number of models that will be trained by multiplying the length of all parameter lists.\n",
        "\n",
        "# Initialize the GridSearchCV object:\n",
        "# - Use 5-fold cross-validation with shuffled splits.\n",
        "# - Run parallel jobs using n_jobs=4 to speed up processing.\n",
        "# - Set verbose=2 to display progress.\n",
        "\n",
        "# Fit the model on the selected features and target values.\n",
        "\n",
        "# Print out the best score and associated hyperparameters after the search completes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndK0WCK7eihK"
      },
      "outputs": [],
      "source": [
        "scores = pd.DataFrame(model.cv_results_)\n",
        "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
        "                                                    ascending = False)\n",
        "scoresCV.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpahMifPesU7"
      },
      "source": [
        "### Comparison with Random Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK8Mxemhem3h"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbNRVDH3eyen"
      },
      "source": [
        "Finally, we can compare the performance and timings of the grid search above with the option of using a Randomized Search instead. We note that Random Search is usually preferable when we have a high-dimensional parameter space; its use is not particularly warranted here.\n",
        "\n",
        "The number of iterations (the number of models that are considered) also needs to be adjusted, and depends on the dimensionality of the parameter space as well as the functional dependence of the loss function on the parameters. We will compare the timings with the cell above, where we explore 144 models, and only use 30 for the random search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwAnDaZTez0e"
      },
      "source": [
        "The references here explores various ways of running a parameter search.\n",
        "\n",
        "Bergstra, J. and Bengio, Y., Random search for hyper-parameter optimization, The Journal of Machine Learning Research (2012)\n",
        "\n",
        "Bergstra, James, et al. \"Algorithms for hyper-parameter optimization.\" Advances in neural information processing systems 24 (2011)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cq5s_ki3evrT"
      },
      "outputs": [],
      "source": [
        "#%%time\n",
        "# This block times the execution of a RandomizedSearchCV optimization using HistGradientBoostingRegressor.\n",
        "\n",
        "# Define the hyperparameter space to explore:\n",
        "# - 'max_depth': Tree depth options.\n",
        "# - 'loss': Error function options.\n",
        "# - 'max_iter': Number of boosting iterations.\n",
        "# - 'learning_rate': How much each tree contributes to the final model.\n",
        "# - 'early_stopping': Whether to stop early if no improvement.\n",
        "\n",
        "# Compute the total number of possible parameter combinations (not all will be used).\n",
        "\n",
        "# Set up RandomizedSearchCV:\n",
        "# - Uses a random subset (n_iter=30) of the full parameter space.\n",
        "# - Applies 5-fold cross-validation with shuffled data splits.\n",
        "# - Uses 4 parallel jobs for faster computation.\n",
        "# - Returns training scores to analyze overfitting.\n",
        "\n",
        "# Fit the model to the selected features and target variable.\n",
        "\n",
        "# Output the best parameters found and the corresponding cross-validation score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duECMTglfXO_"
      },
      "source": [
        "The Randomized Search was able to find a comparably good solution in less than 1/5 of the time. As we mentioned, the true gains of a Randomized Search pertain to exploring high-dimensional spaces. It is also possible to use the Randomized Search to find the general area of optimal parameters, and then refine the search in that neighborhood with a finer Grid Search."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XD5nH8h1fgQ2"
      },
      "source": [
        "### Finally, we can compare with XGBoost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sm4QZIL4fkO6"
      },
      "source": [
        "[XGBoost](https://xgboost.readthedocs.io/en/latest/index.html#) stands for “Extreme Gradient Boosting”. It is sometimes known as \"regularized\" GBM, as it has a default regularization term on the weights of the ensemble, and is more robust to overfitting. It has more flexibility in defining weak learners, as well as the objective (loss) function (note that this doesn't apply to the base estimators, e.g. how splits in trees are chosen, but on the loss that is used to compute pseudoresiduals and gradients)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoUuv4fMfUQW"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrPRL_2nfsT6"
      },
      "source": [
        "Medium article explaining XGBoost: [here](https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7); some nice tutorials from XGBoost's site: [here](https://xgboost.readthedocs.io/en/latest/tutorials/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzGcQ8E9fwUc"
      },
      "source": [
        "We can begin by using Grid Search and the original parameter space, in order to compare timings with GBM and HistGBM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYwuy-8KfovL"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "\n",
        "# This block times the execution of a GridSearchCV optimization using XGBoost (XGBRegressor).\n",
        "\n",
        "# Define the hyperparameter grid to search:\n",
        "# - 'max_depth': Maximum depth of each decision tree.\n",
        "# - 'n_estimators': Number of boosting rounds (trees).\n",
        "# - 'learning_rate': Step size shrinkage used to prevent overfitting.\n",
        "# - 'objective': Specifies the learning task and corresponding loss function.\n",
        "\n",
        "# Calculate total number of parameter combinations in the grid.\n",
        "\n",
        "# Set up GridSearchCV with:\n",
        "# - 5-fold cross-validation (KFold) and data shuffling.\n",
        "# - Verbose output to monitor progress.\n",
        "# - 4 parallel jobs for faster computation.\n",
        "# - Training scores also returned for later evaluation.\n",
        "\n",
        "# Fit the model using the selected input features and target.\n",
        "\n",
        "# Print out the best parameters and corresponding score from the cross-validation process.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF0FEJ83gBLr"
      },
      "source": [
        "XGBoost is slightly more efficient than GBM, and achieves comparable results on a similar grid. We can use the Random Search to explore some more intensive models (more trees, lower learning rate), and add subsampling as an extra form of regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNJodq7SgBuy"
      },
      "outputs": [],
      "source": [
        "# %%time\n",
        "\n",
        "# This block times the execution of a RandomizedSearchCV optimization using XGBoost (XGBRegressor).\n",
        "# Approximate runtime: 3 minutes 36 seconds.\n",
        "\n",
        "# Define the hyperparameter distributions to sample from:\n",
        "# - 'max_depth': Maximum depth of trees.\n",
        "# - 'n_estimators': Number of boosting rounds.\n",
        "# - 'learning_rate': Step size shrinkage.\n",
        "# - 'objective': Loss function used by the model.\n",
        "# - 'subsample': Fraction of training samples used for each tree to prevent overfitting.\n",
        "\n",
        "# Calculate total number of possible parameter combinations (for reference only).\n",
        "\n",
        "# Set up RandomizedSearchCV with:\n",
        "# - 5-fold cross-validation (KFold) and data shuffling.\n",
        "# - Verbose output to track progress.\n",
        "# - Parallel processing with 4 jobs.\n",
        "# - Return training scores.\n",
        "# - Limit the number of sampled combinations to 30 (`n_iter=30`).\n",
        "\n",
        "# Fit the model on selected features and targets.\n",
        "\n",
        "# Print the best hyperparameter combination and the associated cross-validation score.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rAydEGigPl2"
      },
      "outputs": [],
      "source": [
        "scores = pd.DataFrame(model.cv_results_)\n",
        "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
        "                                                    ascending = False)\n",
        "scoresCV.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siBmOUQigYhC"
      },
      "source": [
        "We are able to get slightly higher scores using this wider parameter space in combination with the Randomized Search, but again, the statistical significance of this increase is very low."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3cVKlbBgdxC"
      },
      "source": [
        "We can also look for outlier fraction and NMAD:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vn7sLZBXgePN"
      },
      "outputs": [],
      "source": [
        "y_pred_bm = cross_val_predict(bm, sel_features, sel_target.values.ravel(), cv = KFold(n_splits=5, shuffle = True, random_state=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO0Jpljvgido"
      },
      "outputs": [],
      "source": [
        "print(len(np.where(np.abs(sel_target.values.ravel()-y_pred_bm)>0.15*(1+sel_target.values.ravel()))[0])/len(sel_target.values.ravel()))\n",
        "\n",
        "print(1.48*np.median(np.abs(sel_target.values.ravel()-y_pred_bm)/(1 + sel_target.values.ravel())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CMsSkUNglS2"
      },
      "source": [
        "### Conclusion: all boosting algorithms behave fairly similarly for this data set. It might be worth simply using the fastest one (HistGBR + Random Search)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDbu6atPgk26"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
